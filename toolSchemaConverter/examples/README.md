# LLM Function Adapter - Examples

ì´ í´ë”ì—ëŠ” LLM Function Adapter ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì‚¬ìš© ì˜ˆì œë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ“š ì˜ˆì œ ëª©ë¡

### ê¸°ë³¸ ì‚¬ìš©ë²•

- **01-basic-chat.js** - ê°€ì¥ ê¸°ë³¸ì ì¸ ì±„íŒ… ì‚¬ìš©ë²•
  - ë‹¨ì¼ ë©”ì‹œì§€ ì „ì†¡
  - ì—¬ëŸ¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸
  - Provider ìë™ ê°ì§€

- **02-streaming.js** - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
  - ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë°
  - ì§„í–‰ ìƒí™© ì¶”ì 
  - GPT-5 ìŠ¤íŠ¸ë¦¬ë°

- **03-function-calling.js** - í•¨ìˆ˜ í˜¸ì¶œ/ë„êµ¬ ì‚¬ìš©
  - ê¸°ë³¸ í•¨ìˆ˜ í˜¸ì¶œ
  - ì™„ì „í•œ í•¨ìˆ˜ í˜¸ì¶œ í”Œë¡œìš°
  - Claude í•¨ìˆ˜ í˜¸ì¶œ

- **04-multi-turn-conversation.js** - ë©€í‹°í„´ ëŒ€í™”
  - ê°„ë‹¨í•œ ëŒ€í™”
  - ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ëŒ€í™”
  - ë„êµ¬ í˜¸ì¶œì´ í¬í•¨ëœ ëŒ€í™”

### ê³ ê¸‰ ê¸°ëŠ¥

- **05-gpt5-models.js** - GPT-5 ë° o3 ëª¨ë¸
  - ëª¨ë“  GPT-5 ëª¨ë¸ í…ŒìŠ¤íŠ¸
  - GPT-5 ìŠ¤íŠ¸ë¦¬ë°
  - í•¨ìˆ˜ í˜¸ì¶œ
  - ëª¨ë¸ ë¹„êµ

- **06-all-providers.js** - ëª¨ë“  Provider ì‚¬ìš©
  - OpenAI, Claude, Gemini, Ollama
  - Providerë³„ ìŠ¤íŠ¸ë¦¬ë°
  - Providerë³„ í•¨ìˆ˜ í˜¸ì¶œ
  - ìë™ Provider ê°ì§€

- **07-error-handling.js** - ì—ëŸ¬ ì²˜ë¦¬
  - ì˜ëª»ëœ API í‚¤
  - ëª¨ë¸ ì—†ìŒ
  - Rate Limit
  - ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬
  - Fallback ì „ëµ
  - ì¬ì‹œë„ ë¡œì§

- **08-advanced-parameters.js** - ê³ ê¸‰ íŒŒë¼ë¯¸í„°
  - Temperature ì œì–´
  - Top-P ì œì–´
  - System messages
  - Max tokens
  - Stop sequences
  - Presence/Frequency penalty
  - Multiple choices (n parameter)
  - Seed (ì¬í˜„ì„±)

### ì‹¤ì „ ì˜ˆì œ

- **09-real-world-chatbot.js** - ì‹¤ì „ ì±—ë´‡
  - ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì±—ë´‡
  - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
  - Interactive CLI
  - ë©€í‹°ëª¨ë¸ Fallback

- **10-production-patterns.js** - í”„ë¡œë•ì…˜ íŒ¨í„´
  - Retry with Exponential Backoff
  - Rate Limiting
  - Caching
  - Load Balancing
  - Budget Control

### ê¸°ì¡´ ì˜ˆì œ

- **basic-usage.js** - ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ
- **converter-test.js** - ë³€í™˜ê¸° í…ŒìŠ¤íŠ¸
- **openai-both-apis.js** - OpenAI Chat & Responses API
- **streaming-usage.js** - ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš© ì˜ˆì œ

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
export OPENAI_API_KEY="your-openai-key"
export ANTHROPIC_API_KEY="your-claude-key"
export GEMINI_API_KEY="your-gemini-key"
export OLLAMA_BASE_URL="http://localhost:11434"  # optional
```

### ì˜ˆì œ ì‹¤í–‰

```bash
# ê¸°ë³¸ ì±„íŒ…
node examples/01-basic-chat.js

# ìŠ¤íŠ¸ë¦¬ë°
node examples/02-streaming.js

# í•¨ìˆ˜ í˜¸ì¶œ
node examples/03-function-calling.js

# GPT-5 ëª¨ë¸
node examples/05-gpt5-models.js

# ëª¨ë“  Provider
node examples/06-all-providers.js

# Interactive ì±—ë´‡
node examples/09-real-world-chatbot.js --interactive

# Production íŒ¨í„´
node examples/10-production-patterns.js
```

## ğŸ“– ì£¼ìš” ê¸°ëŠ¥ë³„ ì˜ˆì œ

### GPT-5 ì‚¬ìš©í•˜ê¸°

```javascript
import { UnifiedLLMClient } from './src/index.js';

const client = new UnifiedLLMClient({
  apiKey: process.env.OPENAI_API_KEY
});

const response = await client.chat({
  model: 'gpt-5',  // ë˜ëŠ” 'gpt-5-mini', 'gpt-5-nano', 'o3', 'o3-mini'
  messages: [
    { role: 'user', content: 'Hello!' }
  ],
  max_tokens: 100  // ìë™ìœ¼ë¡œ max_completion_tokensë¡œ ë³€í™˜ë¨
});
```

### í•¨ìˆ˜ í˜¸ì¶œ

```javascript
const tools = [{
  type: 'function',
  function: {
    name: 'get_weather',
    description: 'Get weather information',
    parameters: {
      type: 'object',
      properties: {
        city: { type: 'string' }
      },
      required: ['city']
    }
  }
}];

const response = await client.chat({
  model: 'gpt-4o-mini',
  messages: [{ role: 'user', content: "What's the weather?" }],
  tools: tools
});
```

### ìŠ¤íŠ¸ë¦¬ë°

```javascript
const stream = await client.chat({
  model: 'gpt-4o-mini',
  messages: [{ role: 'user', content: 'Tell me a story' }],
  stream: true
});

for await (const chunk of stream) {
  const content = chunk.choices[0]?.delta?.content || '';
  process.stdout.write(content);
}
```

### ì—ëŸ¬ ì²˜ë¦¬

```javascript
import { LLMError } from './src/index.js';

try {
  const response = await client.chat({...});
} catch (error) {
  if (error instanceof LLMError) {
    console.log('Error type:', error.error.type);
    console.log('Message:', error.error.message);
    console.log('Status:', error.status);
  }
}
```

## ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ ì˜ˆì œ

- **ë¹ ë¥´ê²Œ ì‹œì‘í•˜ê¸°** â†’ `01-basic-chat.js`
- **GPT-5 ì‚¬ìš©í•˜ê¸°** â†’ `05-gpt5-models.js`
- **ì±—ë´‡ ë§Œë“¤ê¸°** â†’ `09-real-world-chatbot.js`
- **í”„ë¡œë•ì…˜ ì¤€ë¹„** â†’ `10-production-patterns.js`
- **ì—ëŸ¬ ì²˜ë¦¬** â†’ `07-error-handling.js`
- **ëª¨ë“  ê¸°ëŠ¥ ë³´ê¸°** â†’ ìˆœì„œëŒ€ë¡œ 01~10 ëª¨ë‘ ì‹¤í–‰

## ğŸ’¡ íŒ

1. **API í‚¤ ê´€ë¦¬**: `.env` íŒŒì¼ ì‚¬ìš© ê¶Œì¥
2. **ë¹„ìš© ê´€ë¦¬**: `max_tokens` ì„¤ì •ìœ¼ë¡œ ë¹„ìš© ì œì–´
3. **ì—ëŸ¬ ì²˜ë¦¬**: í•­ìƒ try-catchë¡œ ì—ëŸ¬ ì²˜ë¦¬
4. **Rate Limit**: í”„ë¡œë•ì…˜ì—ì„œëŠ” Rate Limiting íŒ¨í„´ ì‚¬ìš©
5. **ìºì‹±**: ë™ì¼í•œ ìš”ì²­ì€ ìºì‹±ìœ¼ë¡œ ë¹„ìš© ì ˆê°

## ğŸ“ ë” ì•Œì•„ë³´ê¸°

- [README.md](../README.md) - ì „ì²´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ
- [CHANGELOG.md](../CHANGELOG.md) - ë³€ê²½ ì´ë ¥
- [GPT5_API_Report.md](../GPT5_API_Report.md) - GPT-5 API ëª…ì„¸
